# ğŸŒ™ Saad Saudi Arabic Model | Ù†Ù…ÙˆØ°Ø¬ Ø³Ø¹Ø¯

**Training code for Saudi Arabic conversational AI model**

**ÙƒÙˆØ¯ ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ù…Ø­Ø§Ø¯Ø«Ø© Ø³Ø¹ÙˆØ¯ÙŠ**

---

## ğŸ‘¨â€ğŸ’» Developer | Ø§Ù„Ù…Ø·ÙˆØ±

**Abdullah Al-Shareef | Ø¹Ø¨Ø¯Ø§Ù„Ù„Ù‡ Ø§Ù„Ø´Ø±ÙŠÙ**

Saudi developer specialized in AI and NLP

---

## âœ¨ Features | Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª

- ğŸ‡¸ğŸ‡¦ Saudi dialect understanding | ÙÙ‡Ù… Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©
- ğŸ’¬ Modern Standard Arabic support | Ø¯Ø¹Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰
- ğŸ¤– Natural conversation | Ù…Ø­Ø§Ø¯Ø«Ø© Ø·Ø¨ÙŠØ¹ÙŠØ©
- ğŸ’ LoRA + 4-bit quantization | ØªØ¯Ø±ÙŠØ¨ ÙØ¹Ø§Ù„

---

## ğŸ› ï¸ Installation | Ø§Ù„ØªØ«Ø¨ÙŠØª

```bash
git clone https://github.com/iamdev7/saad-saudi-model-training.git
cd saad-saudi-model-training
pip install -r requirements.txt
```

---

## ğŸ“Š Quick Start | Ø§Ù„Ø¨Ø¯Ø¡ Ø§Ù„Ø³Ø±ÙŠØ¹

### 1ï¸âƒ£ Prepare Data | ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª

```bash
# Place your data files in data/raw/
# Ø¶Ø¹ Ù…Ù„ÙØ§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ data/raw/

python prepare_data.py
```

**Supported formats | Ø§Ù„ØªÙ†Ø³ÙŠÙ‚Ø§Øª Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©:**
- JSON: `[{"user": "...", "assistant": "..."}]`
- TXT: `User: ... | Assistant: ...`

### 2ï¸âƒ£ Train | Ø§Ù„ØªØ¯Ø±ÙŠØ¨

```bash
python train_model.py
```

**Training features | Ù…Ù…ÙŠØ²Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨:**
- LoRA fine-tuning (~1-2% of parameters)
- 4-bit quantization for efficiency
- Automatic checkpointing
- GPU + CPU support

### 3ï¸âƒ£ Upload | Ø§Ù„Ø±ÙØ¹

```bash
python upload_to_hf.py
```

---

## ğŸ’» Usage Example | Ù…Ø«Ø§Ù„ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…

```python
from transformers import AutoModelForCausalLM, AutoTokenizer

# Load model
model = AutoModelForCausalLM.from_pretrained("A7be7/saad")
tokenizer = AutoTokenizer.from_pretrained("A7be7/saad")

# Generate
prompt = "Ù…Ø±Ø­Ø¨Ø§ØŒ ÙƒÙŠÙ Ø­Ø§Ù„ÙƒØŸ"
inputs = tokenizer(prompt, return_tensors="pt")
outputs = model.generate(**inputs, max_length=100)
response = tokenizer.decode(outputs[0])
print(response)
```

---

## ğŸ“‚ Project Structure | Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹

```
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # Your data here
â”‚   â””â”€â”€ processed/       # Processed data
â”œâ”€â”€ models/
â”‚   â””â”€â”€ saad-saudi-model/  # Trained model
â”œâ”€â”€ prepare_data.py
â”œâ”€â”€ train_model.py
â”œâ”€â”€ upload_to_hf.py
â””â”€â”€ requirements.txt
```

---

## âš™ï¸ Configuration | Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª

Edit `train_model.py` for custom settings:

```python
base_model = "aubmindlab/aragpt2-base"
num_epochs = 3
batch_size = 4
learning_rate = 2e-4
max_length = 512
```

---

## ğŸ’¾ Requirements | Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª

- Python 3.8+
- CUDA 11.8+ (recommended)
- 16GB RAM
- GPU with 8GB+ VRAM (12GB recommended)

---

## ğŸ“ License | Ø§Ù„ØªØ±Ø®ÙŠØµ

CreativeML OpenRAIL-M

---

## ğŸ”— Links | Ø§Ù„Ø±ÙˆØ§Ø¨Ø·

- **Model on Hugging Face**: [A7be7/saad](https://huggingface.co/A7be7/saad)
- **GitHub**: [iamdev7/saad-saudi-model-training](https://github.com/iamdev7/saad-saudi-model-training)

---

<div align="center">

**Made with â¤ï¸ in Saudi Arabia ğŸ‡¸ğŸ‡¦**

**ØµÙÙ†Ø¹ Ø¨ÙƒÙ„ Ø­Ø¨ ÙÙŠ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©**

</div>
